{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'PIL'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mPIL\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Image \u001b[38;5;66;03m# هذه المكتبة تتعلق بمعالجة الصور\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split  \u001b[38;5;66;03m# تقسيم البيانات\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m  \u001b[38;5;66;03m# مكتبة تعلم عميق\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'"
     ]
    }
   ],
   "source": [
    "from PIL import Image # هذه المكتبة تتعلق بمعالجة الصور\n",
    "from sklearn.model_selection import train_test_split  # تقسيم البيانات\n",
    "import tensorflow as tf  # مكتبة تعلم عميق\n",
    "import numpy as np  # للعمل مع المصفوفات\n",
    "import matplotlib.pyplot as plt  # للرسم البياني وعرض الصور\n",
    "import os  # للعمل مع نظام الملفات\n",
    "import time  # حساب الوقت\n",
    "from tensorflow import keras  # مكتبة تعلم عميق فرعية\n",
    "\n",
    "# تشغيل الوظائف بوضع التنفيذ الفوري (للإصدارات الأحدث من TensorFlow)\n",
    "tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# حجم الدفعة الذي سنستخدمه أثناء التدريب\n",
    "batch_size = 64\n",
    "\n",
    "# حجم الصورة المطلوب لتدريب النموذج\n",
    "img_size = 120\n",
    "\n",
    "# عدد الصور التي سيتم استخدامها من الأرشيف\n",
    "dataset_split = 2500\n",
    "\n",
    "master_dir = r'D:\\1-ForME\\Project\\AI for AMIT\\colorization\\Dataset\\archive\\color'\n",
    "x = []\n",
    "y = []\n",
    "for image_file in os.listdir(master_dir)[0:dataset_split]:\n",
    "    rgb_image = Image.open(os.path.join(master_dir, image_file)).resize((img_size, img_size))\n",
    "    # تطبيع صورة RGB\n",
    "    rgb_img_array = (np.asarray(rgb_image)) / 255\n",
    "    gray_image = rgb_image.convert('L')\n",
    "    # تطبيع صورة تدرج الرمادي\n",
    "    gray_img_array = (np.asarray(gray_image).reshape((img_size, img_size, 1))) / 255\n",
    "    # إضافة الصور إلى القوائم\n",
    "    x.append(gray_img_array)\n",
    "    y.append(rgb_img_array)\n",
    "\n",
    "# تقسيم البيانات إلى تدريب واختبار\n",
    "train_x, test_x, train_y, test_y = train_test_split(np.array(x), np.array(y), test_size=0.1)\n",
    "\n",
    "# إنشاء كائن tf.data.Dataset\n",
    "dataset = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "dataset = dataset.batch(batch_size)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **2. The GAN**\n",
    "\n",
    "In this section, we'll create our GAN model step-by-step with Keras. First, we'll implement the generator then the discriminator and finally the loss functions required by both of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### **A. Generator** \n",
    "\n",
    "Our generator ( represented as $G$ ) will take in grayscale image $x$ and produce a RGB image $G( x )$. Note, $x$ will be a tensor of shape $( \\ batch \\ size \\ , \\ 120 \\ , \\ 120 \\ , \\ 1 \\ )$ and the output $G(x)$ will have a shape $( \\ batch \\ size \\ , \\ 120 \\ , \\ 120 \\ , \\ 3 \\ )$\n",
    "\n",
    "* Our generator will have a encoder-decoder structure, similar to the UNet architecture. Additionally, we use Dilated convolutions to have a larger receptive field.\n",
    "\n",
    "* We introduce skip connections in our model so as to have better flow of information from the encoder to the decoder.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "app",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
